{"version":3,"sources":["components/VideoSegmentation.tsx","App.tsx","reportWebVitals.ts","index.tsx"],"names":["metadata","id","modelPath","configPath","preprocessorPath","Container","styled","div","display","Img","props","width","height","LayeredImage","opacity","VideoSegmentation","useState","model","setModel","imgWidth","setImgWidth","imgHeight","setImgHeight","videoRef","useRef","segSrc","setSegSrc","frameDataURL","setFrameDataURL","setFpInterval","useEffect","capture","getModel","SegmentationModel","init","window","innerWidth","fpIntervalLoc","setInterval","constraints","audio","video","facingMode","navigator","mediaDevices","getUserMedia","then","mediaStream","track","getVideoTracks","ImageCapture","takePhoto","blob","console","log","captureURL","URL","createObjectURL","catch","error","err","message","getResults","process","output","imgTemp","canvas","toDataURL","current","srcObject","onloadedmetadata","play","ref","playsInline","autoPlay","onPlay","src","App","className","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","createRoot","document","getElementById","render","StrictMode"],"mappings":"yWAQMA,EAA0B,CAC9BC,GAAI,MACJC,UACE,+FACFC,WACE,gGACFC,iBACE,8GAQEC,EAAYC,IAAOC,IAAI,CAC3BC,QAAS,SAGLC,EAAMH,YAAO,MAAPA,CAAa,sFACd,SAACI,GAAgB,OAAKA,EAAMC,KAAK,IAChC,SAACD,GAAgB,OAAKA,EAAME,MAAM,IAIxCC,EAAeP,YAAOG,EAAPH,CAAY,CAC/BQ,QAAS,KAgJIC,GA7IAT,YAAO,SAAPA,CAAgB,0HACpB,SAACI,GAAgB,OAAKA,EAAMC,KAAK,IAChC,SAACD,GAAgB,OAAKA,EAAME,MAAM,IAOV,WAClC,MAA0BI,qBAAe,mBAAlCC,EAAK,KAAEC,EAAQ,KACtB,EAAgCF,mBAAiB,GAAE,mBAA5CG,EAAQ,KAAEC,EAAW,KAC5B,EAAkCJ,mBAAiB,GAAE,mBAA9CK,EAAS,KAAEC,EAAY,KAGxBC,EAAWC,iBAAyB,MAE1C,EAA4BR,qBAAkB,mBAAvCS,EAAM,KAAEC,EAAS,KACxB,EAAwCV,qBAAkB,mBAAnDW,EAAY,KAAEC,EAAe,KACpC,EAAoCZ,qBAAwB,mBAAzCa,GAAF,KAAe,MAEhCC,qBAAU,WACRC,IACA,IAAMC,EAAQ,iDAAG,8FAC8B,OAAvCf,EAAQ,IAAIgB,oBAAkBjC,GAAU,EAAD,OACvCiB,EAAMiB,OAAO,KAAD,EACdjB,GACFC,EAASD,GACV,2CACF,kBANa,mCAQde,GACF,GAAG,IAEHF,qBAAU,WACRV,EAAgC,GAApBe,OAAOC,YACnBd,EAAiC,IAApBa,OAAOC,WACtB,GAAG,IAEHN,qBAAU,WACR,IAAMO,EAAgBC,aAAY,WAChC,IAAMC,EAAc,CAClBC,OAAO,EACPC,MAAO,CAAE9B,MAAOQ,EAAUP,OAAQS,EAAWqB,WAAY,SAE3DC,UAAUC,aACPC,aAAaN,GACbO,MAAK,SAAUC,GACd,IAAMC,EAAQD,EAAYE,iBAAiB,GACtB,IAAIC,aAAaF,GAEnCG,YACAL,MAAK,SAACM,GACLC,QAAQC,IAAI,cAAeF,GAC3B,IAAMG,EAAaC,IAAIC,gBAAgBL,GACvCxB,EAAgB2B,EAClB,IACCG,OAAM,SAACC,GACNN,QAAQM,MAAM,sBAAuBA,EACvC,GACJ,IACCD,OAAM,SAAUE,GACfP,QAAQC,IAAIM,EAAIC,QAClB,GACJ,GAAG,KACHhC,EAAcQ,EAChB,GAAG,IAEHP,qBAAU,WACR,IAAMgC,EAAU,iDAAG,oGACb7C,IAASU,EAAY,gBACqB,OAA5C0B,QAAQC,IAAI,iBAAkB3B,GAAc,SACvBV,EAAM8C,QAAQpC,GAAc,KAAD,EAA1CqC,EAAM,OACZX,QAAQC,IAAIU,GACNC,EAAUD,EAAOE,OAAOC,UAAU,aAmBxCzC,EAAUuC,GAAS,2CAEtB,kBA1Be,mCA4BhBH,GACF,GAAG,CAACnC,IAEJ,IAIMI,EAAU,WACd,IAAMQ,EAAc,CAClBC,OAAO,EACPC,MAAO,CAAE9B,MAAOQ,EAAUP,OAAQS,EAAWqB,WAAY,SAE3DC,UAAUC,aACPC,aAAaN,GACbO,MAAK,SAACC,GACL,IAAMN,EAAQlB,EAAS6C,QACnB3B,IACFA,EAAM4B,UAAYtB,EAClBN,EAAM6B,iBAAmB,WACvB7B,EAAM8B,MACR,EAEJ,IACCb,OAAM,SAAUE,GACfP,QAAQC,IAAIM,EAAIC,QAClB,GACJ,EAEA,OACE,YAACxD,EAAS,KACR,qBACEM,MAAM,MACNC,OAAO,GACP4D,IAAKjD,EACLkD,aAAW,EACXC,UAAQ,EACRC,OAjCS,WACbtB,QAAQC,IAAI,SACd,IAiCI,YAACzC,EAAY,CAAC+D,IAAKnD,EAAQd,MAAOQ,EAAUP,OAAQS,IAI1D,G,QCnKewD,MARf,WACE,OACE,qBAAKC,UAAU,MAAK,SAClB,cAAC,EAAiB,KAGxB,ECGeC,EAZS,SAACC,GACnBA,GAAeA,aAAuBC,UACxC,8BAAqBnC,MAAK,YAAkD,IAA/CoC,EAAM,EAANA,OAAQC,EAAM,EAANA,OAAQC,EAAM,EAANA,OAAQC,EAAM,EAANA,OAAQC,EAAO,EAAPA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,EACV,GAEJ,ECNaO,IAASC,WACpBC,SAASC,eAAe,SAErBC,OACH,cAAC,IAAMC,WAAU,UACf,cAAC,EAAG,OAORb,G","file":"static/js/main.ede11388.chunk.js","sourcesContent":["import React, { useState, useEffect, useRef } from 'react';\nimport { ImageMetadata, SegmentationModel } from 'in-browser-ai';\n\n/** @jsxRuntime classic */\n/** @jsx jsx */\nimport { jsx } from '@emotion/react';\nimport styled from '@emotion/styled';\n\nconst metadata: ImageMetadata = {\n  id: '123',\n  modelPath:\n    'https://huggingface.co/visheratin/segformer-b0-finetuned-ade-512-512/resolve/main/b0.onnx.gz',\n  configPath:\n    'https://huggingface.co/visheratin/segformer-b0-finetuned-ade-512-512/resolve/main/config.json',\n  preprocessorPath:\n    'https://huggingface.co/visheratin/segformer-b0-finetuned-ade-512-512/resolve/main/preprocessor_config.json',\n};\n\ninterface SizeProps {\n  width: number;\n  height: number;\n}\n\nconst Container = styled.div({\n  display: 'flex',\n});\n\nconst Img = styled('img')<SizeProps>`\n  width: ${(props: SizeProps) => props.width}px;\n  height: ${(props: SizeProps) => props.height}px;\n  position: absolute;\n`;\n\nconst LayeredImage = styled(Img)({\n  opacity: 0.5,\n});\n\nconst Canvas = styled('canvas')<SizeProps>`\n  width: ${(props: SizeProps) => props.width};\n  height: ${(props: SizeProps) => props.height};\n  left: 0;\n  top: 0;\n  opacity: 0.5;\n  position: absolute;\n`;\n\nconst VideoSegmentation: React.FC = () => {\n  const [model, setModel] = useState<any>();\n  const [imgWidth, setImgWidth] = useState<number>(0);\n  const [imgHeight, setImgHeight] = useState<number>(0);\n  //   // to use canvas uncomment\n  //   const canvas = useRef<HTMLCanvasElement>(null);\n  const videoRef = useRef<HTMLVideoElement>(null);\n\n  const [segSrc, setSegSrc] = useState<string>();\n  const [frameDataURL, setFrameDataURL] = useState<string>();\n  const [fpInterval, setFpInterval] = useState<NodeJS.Timer>();\n\n  useEffect(() => {\n    capture();\n    const getModel = async () => {\n      const model = new SegmentationModel(metadata);\n      await model.init();\n      if (model) {\n        setModel(model);\n      }\n    };\n\n    getModel();\n  }, []);\n\n  useEffect(() => {\n    setImgWidth(window.innerWidth * 0.6);\n    setImgHeight(window.innerWidth * 0.45);\n  }, []);\n\n  useEffect(() => {\n    const fpIntervalLoc = setInterval(() => {\n      const constraints = {\n        audio: false,\n        video: { width: imgWidth, height: imgHeight, facingMode: 'user' },\n      };\n      navigator.mediaDevices\n        .getUserMedia(constraints)\n        .then(function (mediaStream) {\n          const track = mediaStream.getVideoTracks()[0];\n          const imageCapture = new ImageCapture(track);\n          imageCapture\n            .takePhoto()\n            .then((blob) => {\n              console.log('Took photo:', blob);\n              const captureURL = URL.createObjectURL(blob);\n              setFrameDataURL(captureURL);\n            })\n            .catch((error) => {\n              console.error('takePhoto() error: ', error);\n            });\n        })\n        .catch(function (err) {\n          console.log(err.message);\n        });\n    }, 1000);\n    setFpInterval(fpIntervalLoc);\n  }, []);\n\n  useEffect(() => {\n    const getResults = async () => {\n      if (model && frameDataURL) {\n        console.log('frame data url', frameDataURL);\n        const output = await model.process(frameDataURL);\n        console.log(output);\n        const imgTemp = output.canvas.toDataURL('image/png');\n\n        // // to use canvas uncomment\n        // const ctx = canvas.current?.getContext('2d');\n        // if (ctx && canvas.current) {\n        //   ctx.globalAlpha = 0.4;\n        //   ctx.drawImage(\n        //     output.canvas,\n        //     0,\n        //     0,\n        //     output.canvas.width,\n        //     output.canvas.height,\n        //     0,\n        //     0,\n        //     canvas.current.width,\n        //     canvas.current.height,\n        //   );\n        // }\n\n        setSegSrc(imgTemp);\n      }\n    };\n\n    getResults();\n  }, [frameDataURL]);\n\n  const onPlay = () => {\n    console.log('onPlay');\n  };\n\n  const capture = () => {\n    const constraints = {\n      audio: false,\n      video: { width: imgWidth, height: imgHeight, facingMode: 'user' },\n    };\n    navigator.mediaDevices\n      .getUserMedia(constraints)\n      .then((mediaStream) => {\n        const video = videoRef.current;\n        if (video) {\n          video.srcObject = mediaStream;\n          video.onloadedmetadata = () => {\n            video.play();\n          };\n        }\n      })\n      .catch(function (err) {\n        console.log(err.message);\n      });\n  };\n\n  return (\n    <Container>\n      <video\n        width=\"60%\"\n        height=\"\"\n        ref={videoRef}\n        playsInline\n        autoPlay\n        onPlay={onPlay}\n      ></video>\n      <LayeredImage src={segSrc} width={imgWidth} height={imgHeight} />\n      {/* <Canvas ref={canvas} width={imgWidth} height={imgHeight}></Canvas> */}\n    </Container>\n  );\n};\n\nexport default VideoSegmentation;\n","import React from 'react';\n\nimport './App.css';\nimport VideoSegmentation from './components/VideoSegmentation';\n\nfunction App() {\n  return (\n    <div className=\"App\">\n      <VideoSegmentation />\n    </div>\n  );\n}\n\nexport default App;\n","import { ReportHandler } from 'web-vitals';\n\nconst reportWebVitals = (onPerfEntry?: ReportHandler) => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom/client';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nconst root = ReactDOM.createRoot(\n  document.getElementById('root') as HTMLElement\n);\nroot.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}